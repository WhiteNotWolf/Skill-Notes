## 面试中有关项目可能会问到的问题
1. 简单的介绍一下你的项目 
    >本项目是C++编写的一个Web服务器，参考了muduo库的实现模式，使用了Reactor模式，并使用多线程提高并发度。使用了线程池，在程序的开始创建固定数量的线程。用epoll作为IO多路复用的实现方式，实现了输入输出的缓冲区，使用eventfd机制来唤醒IO线程，并且使用webbench进行了压力测试。
2. 介绍一下项目是怎么运行的？
    >首先会创建一个mainloop事件循环并在mainloop中创建epoll来接收请求，然后创建myhttpserver绑定mainloop并把mainloop注册到回调函数channel中，绑定ip地址和端口号获得listenfd并且通过回调把listenfd加入到mainloop的监听中，设置线程池的数目和监听的端口,然后启动myhttp服务器，把mainloop作为线程池的baseloop创建并启动线程池，通过回调函数调用mainloop设置epoll的模式为LT，设置epoll的readhandler为newcon,connhandler为thiscon，把server的started状态变为true，mainloop进入循环，这样服务器就启动了。
    >当有一个新事件到来时， 处于循环中的mainloop调用epoll_wait监听到了这个事件，并返回活跃事件的数目和文件描述符(保存在vector中)，循环遍历vector，如果是请求连接就建立一个tcp连接，获得一个acceptfd，如果连接数已经达到了服务器的最大连接数目，就关闭这个连接，如果没有的话，就从线程池的等待线程中取出一个io线程，绑定httpdata处理函数，然后调用queueinloop把该处理函数加入到Eventloop的vector中，如果当前线程不是io线程或者是在dopendingfunc时调用的queueinloop，就调用weakup，触发一个eventfd事件，唤醒io线程，EventLoop::loop循环会继续调用到doPendingFunctors()方法，这里面遍历保存IRun*的vector,开始处理请求事件。
    >httpdata处理函数，会调用newEvent监听该连接并设置一个定时器，开始读取请求，先把数据读取到接受缓存区中，对请求数据进行分析，如果请求有错误就返回错误400，如果没有错误分析是哪一种请求，对请求行进行分析，查看请求行的请求方法，分析URL得到请求的文件，然后分析协议版本，如果是post方法还要对请求内容进行分析，分析完成之后把对方需要的数据写入到缓冲区中，然后发送回去。
  
2. Reactor模式和Proactor模式有什么区别？
    * 工作流程
        >Reactor是一种反应器，它的工作流程是启动应用，将关注的事件注册到Reactor中，然后调用Reactor进入无限事件循环，等待注册事件的到来，事件到来epoll返回，Reactor将事件分发到之前注册的回调函数中处理，具体的事件处理程序不调用Reactor，而是由Reactor分配一个具体事件处理程序。
        >Proactor是一个主动器，它的工作流程是启动应用程序，一个事件来临，调用异步操作处理器提供的异步操作接口函数，调用之后应用程序和异步操作处理就独立运行；应用程序可以调用新的异步操作，而其它操作可以并发进行，应用程序启动Proactor主动器，进行无限的事件循环，等待完成事件到来。异步操作处理器执行异步操作，完成后将结果放入到完成事件队列，主动器从完成事件队列中取出结果，分发到相应的完成事件回调函数处理逻辑中。
    * 区别
        >Reactor被动的等待指示事件的到来并做出反应；它有一个等待的过程，做什么都要先放入到监听事件集合中等待handler可用时再进行操作.
        >Proactor直接调用异步读写操作，调用完后立刻返回.
    * 优点
        >Reactor实现相对简单，对于耗时短的处理场景处理高效； 操作系统可以在多个事件源上等待，并且避免了多线程编程相关的性能开销和编程复杂性； 事件的串行化对应用是透明的，可以顺序的同步执行而不需要加锁； 事务分离：将与应用无关的多路分解和分配机制和与应用相关的回调函数分离开来，
        >Proactor性能更高，能够处理耗时长的并发场景；
    * 缺点
        >Reactor处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理；
        >Proactor实现逻辑复杂；依赖操作系统对异步的支持，目前实现了纯异步操作的操作系统少
    * 适用场景
        >Reactor：同时接收多个服务请求，并且依次同步的处理它们的事件驱动程序； 
        >Proactor：异步接收和同时处理多个服务请求的事件驱动程序；

3. 如何实现一个线程池? 
    >首先要定义一个集合存放所有线程的,还要有一个存放任务的队列存储提交个线程池的任务，还有有一个管理任务队列的线程，然后是所有的线程关注任务队列，如果自己没有在执行任务而且任务队列中有任务，就去调用任务分配的线程，然后任务分配的线程就执行任务调度算法从任务队列中取出一个任务交给该线程执行，当新的任务到来时，调用任务管理线程加入到任务队列中。

4. select/poll/epoll的区别
    >select和poll很相似，会O(n)的无差别的轮循所有的流，找出有读入读出的流，返回活跃文件描述符，而且处理的时候会把文件描述符从用户空间拷贝到内核空间中进行处理，很消耗时间，select监听的fd有最大数目的限制,32位机器能监听的数目是1024,64位是2048，poll因为使用的是链表保存的fd，所有没有最大监听数的限制。
    >epoll会直接返回活跃的文件描述符，所有不需要轮循去获取活跃的时候，此外epoll会在内存开辟一块空间，所以不需要把活跃的文件描述符从用户拷贝内核空间，epoll用红黑树来保存需要监听的事件，每个事件对应的节点中都有一个链表，用来保存监听到的fd，同时会记录链表中fd的数目，所以只需要访问链表的数目就可以得到监听到的事件的数目。

5. epoll的ET和LT的区别
    >LT是高电平触发，监听缓存区不为空的时候会触发epollin事件，ET是边沿触发，当接受缓冲区由空变为不为空的时候会被触发epollin，所以处于ET的时候读的时候一定要把接受缓冲区读为空或者不能在读。造成这样的原因是epoll的活跃事件是存储在链表中的，LT的模式下，只有当你事件完成的时候，才会把事件从链表中删除，如果你没有完成它下一次还能在链表中读取到，而ET状态下，一旦你开始执行这个事件，它就会被从链表删除，所以ET模式下一定要保证读到不能再读，才能触发新的事件

4. eventfd的用处
    >eventfd可以用来实现进程或线程之间的通信，int eventfd(unsigned int initval, int flags)函数可以直接创建一个事件对象，返回一个文件描述符，用来实现进程或线程间的等待和通知。内核为这个对象维护了一个无符号的64位整形计数器 counter，用第一个参数（initval）初始化这个计数器，创建时一般可将其设为0，flags可以使用宏设置为非阻塞的模式。
    >对eventfd的操作有read、write、close，read读取8字节的值，如果count > 0,返回count并设置count为0，如果count为0就阻塞直到count > 0。write就是写入一个64位无符号整数（8字节），如果count达到了最大的能存储的值，就陷入阻塞直到read发生。close就是关闭eventfd。对比pipe，少用了一个文件描述符，而且不用管理缓冲区，单纯的事件通知会方便很多。
    >在这里是为了唤醒IO线程，一个请求连接到来，分配一个io线程给它，但是该io线程可能处于阻塞状态，这个时候可以向eventfd中写入8个字节唤醒io线程，因为io线程始终监视着eventfd的可读事件，只要向eventfd中写入8个字节，io线程就能读取到这个8个字节从阻塞状态返回。

5. 哪些地方使用到了线程锁？
    >对保存挂起函数pending的vector操作都用到了锁.

6. 如何实现一个无锁队列？
    >原子操作，处理器的原子操作，使用总线锁或者缓存锁。
    * 总线锁就是使用的处理器提供一个LOCK信号，当一个处理器在总线上输出此信号的时候，其他的处理器的请求会被所在，该处理器可以独占这块共享内存，这样就可以对共享内存内的数据进行修改。缓存锁是如果内存区域是被缓存在处理器的缓存行内，并且在lock操作期间被锁定，那么它回写到内存的时候，处理器不再声明总线锁，而是修改内部的内存地址，并允许它的缓存一致性来保证操作的原子性。缓存一致性机制就整体来说，是当某块CPU对缓存中的数据进行操作了之后，就通知其他CPU放弃储存在它们内部的缓存，或者从主内存中重新读取。并非所有情况都会使用缓存一致性的，如被操作的数据不能被缓存在CPU内部或操作数据跨越多个缓存行(状态无法标识)，则处理器会调用总线锁定;另外当CPU不支持缓存锁定时，自然也只能用总线锁定了
    * 缓存一致性：MESI协议，是以缓存行(缓存的基本数据单位，在Intel的CPU上一般是64字节)的几个状态来命名的(全名是Modified、Exclusive、 Share or Invalid)。该协议要求在每个缓存行上维护两个状态位，使得每个数据单位可能处于M、E、S和I这四种状态之一，各种状态含义如下：
        M：被修改的。处于这一状态的数据，只在本CPU中有缓存数据，而其他CPU中没有。同时其状态相对于内存中的值来说，是已经被修改的，且没有更新到内存中.
        E：独占的。处于这一状态的数据，只有在本CPU中有缓存，且其数据没有修改，即与内存中一致。
        S：共享的。处于这一状态的数据在多个CPU中都有缓存，且与内存一致。
        I：无效的。本CPU中的这份缓存已经无效。
    一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回CPU。一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。
    当CPU需要读取数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他CPU的监听结果，如其他CPU也有该数据的缓存且状态是M，则需要等待其把缓存更新到内存之后，再读取。
    当CPU需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令(Read Or Ownership，这是一种总线事务)，通知其他CPU置缓存无效(I)，这种情况下性能开销是相对较大的。在写入完成后，修改其缓存状态为M。
    
    >实现无锁队列
        CAS原子操作，CAS(V,A,B),当内存值V等于期望值A,就把内存值V，修改为B,即if(A == B) V = B;,否则不进行修改。
        '''
        EnQueue(x)//进队列
        {//准备新加入的结点数据
        q = new record();
        q->value = x;
        q->next = NULL;
        do {
            while(p->next != NULL)
            p = tail;//取链表尾指针的快照
        } while( CAS(p->next, NULL, q) != TRUE);//如果没有把结点链在尾指针上，再试
            CAS(tail, p, q);//置尾结点
        }
        DeQueue()//出队列
        {
            do{
                p = head;
                if (p->next == NULL)
                    return ERR_EMPTY_QUEUE;
                }while( CAS(head, p, p->next) != TRUE );
                return p->next->value;
        }
        '''
   
7. 有请求但是读取不到数据，可能的情况有？
    >可能是请求中止或者是网络延迟导致数据没有到达，最有可能的是对端关闭，所以统一按着对端关闭处理，断开连接。

8. 输入输出缓冲区是怎么实现的。
    >我这里输入输出缓冲用的是效率比较低下的string，没有经过特别的设计，所以在长连接，需要不断的往缓冲区写入和读出的时候效率会低。

9. 用到了哪些智能指针？你还知道哪些智能指针以及他们各自的用法？
    >shared_ptr多个指针指向相同的对象。shared_ptr使用引用计数，每一个shared_ptr的拷贝都指向相同的内存。每使用他一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。对shared_ptr进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类。可以通过make_shared函数或者通过构造函数传入普通指针。并可以通过get函数获得普通指针。

10. 怎么做的压力测试，测试结果如何？
    * 测试环境:ubuntu 18.04 I7-6700HQ 4核8G
    * 测试方法:使用webbench，开启1000个客户端进程，测试时间60s，分别测试长连接和短连接，关闭所有的输出和文件，线程池开启4线程。
    * 测试结果：WebServer处理短连接的QPS（每秒查询率）大概在8-9W左右（Speed = 5607926 pages/min)
              muduo库处理短连接的QPS大概在8.8W
              WebServer处理长连接的QPS，大概在32W左右（Speed = 19220316 pages/min)
              muduo库处理长连接的QPS，大概在35W左右
    * 对结果的分析：可以看出长连接能处理的请求数是短连接的三到四倍，因为没有连接建立和断开的开销
                因为缓冲区没有进行优化，在处理短连接的时候差距还不是很大，但是在处理长连接的时候就可以看出来差距了
                用top查看各线程CPU占用时，空闲状态下几乎不占内存，短连接的时候，各线程的CPU负载比较均衡
                长连接时，主线程负载为0，线程池负载接近100.
    * 改进：对缓冲区进行优化

11. 如何对服务器性能进行优化
    * 换用更好的主机。
    * 用固态硬盘代替机械硬盘，跟传统机械硬盘相比，固态硬盘具有快速读写、质量轻、能耗低以及体积小等特点。
    * 增加缓存，很多web应用是有大量的静态内容的，这些静态内容呢主要是一些小文件，会被频繁的读取，所以可以把服务器中这样的静态文件资源缓存到操作系统的内存中，因为从内存读取的速度远大于从磁盘读取的速度。
    * 使用内存数据库，相对于磁盘，内存的数据读写速度要高出几个数量级，将数据保存在内存中相比从磁盘上访问能够极大地提高应用的性能。这个和增加缓存差不多，都是用增加内存的成本来降低访问磁盘所需要的时间。
    * 优化数据库，因为大部分的服务器请求最终还是要落到数据库上，所以可以对数据库进行优化。根据合适的规则对数据库进行分区分表啊，可以有效的提高数据库的访问速度，提升服务器的整体性能。还可以在建表的时候根据相关的需求建立索引等，提高查询速度。
    * 选择合适的IO模型
    * 利用服务器多核的特点，采用多进程或者多线程的框架。使用线程池，测试不同线程池的性能来设置线程池合适的大小。
    * 通过分布式部署来提高服务器的响应能力，比如处理图片的速度可能比处理文字要慢，这样可以拿出单独的服务器去处理图片。

12. 假如服务器要升级，又不想让用户感觉到服务器升级了，该怎么做？
    >可以采用分批升级的方法，选择一个用户活跃数少的时候，比如凌晨2点，先升级其中的一部分，可以先让一部分服务器不再接受连接，等服务器上已有的连接处理完成了，这样就可以对这一批服务器进行升级，等这一批服务器升级完成，测试没问题之后，投入使用，去换取正在运行的一批服务器下来升级。
13. 什么是优雅关闭连接？
    >当连接因为意外或者主动断开连接时，而此时，输入输出缓冲区中还有数据没有被发送或者接受，如果直接的调用close()/closesocket(),会直接发送一个FIN，关闭套接字，这样输入输出缓冲区中的数据就会丢失，这样就不是优雅的关闭连接。优雅的关闭连接就是当连接断开时，通过设置阻塞close()一段时间，等待数据发送读取完，或者超时之后才调用close()关闭套接字，这样就不会丢失输入输出缓冲区中的数据，优雅的关闭了连接。

14. 市面上服务器的性能。
    >